import httpx
import json
import base64
import os
from typing import Optional
from textual.widgets import Static, Markdown
from textual.containers import ScrollableContainer
from textual.reactive import reactive
import asyncio

from config import TOKEN_FILE_PATH


class AnimatedSpinner(Static):
    """A custom Static widget that animates a spinner using a sequence of characters."""

    spinner_chars = ["‚†ã", "‚†ô", "‚†π", "‚†∏", "‚†º", "‚†¥", "‚†¶", "‚†ß", "‚†á", "‚†è"]
    current_index = reactive(0)

    def on_mount(self) -> None:
        """Start the animation when the widget is mounted."""
        # TƒÉng interval l√™n ƒë·ªÉ gi·∫£m CPU usage
        self.set_interval(0.15, self.update_spinner)  # t·ª´ 0.1 l√™n 0.15

    def update_spinner(self) -> None:
        """Cycle through spinner characters."""
        self.current_index = (self.current_index + 1) % len(self.spinner_chars)
        self.update(self.spinner_chars[self.current_index])


# UI constants for spinner styles
THINKING_COLOR = "white"
TOOL_COLOR = "yellow"
RESPONSE_TOOL_COLOR = "green"
THINKING_PREFIX = "üí≠"
TOOL_PREFIX = "üîé"
THINKING_SPINNER = ["‚†ã", "‚†ô", "‚†π", "‚†∏", "‚†º", "‚†¥", "‚†¶", "‚†ß", "‚†á", "‚†è"]
TOOL_SPINNER = ["‚óê", "‚óì", "‚óë", "‚óí"]


async def send_chat_request(
    http_client: httpx.AsyncClient,
    message: str,
    conversation_id: Optional[int],
    attached_file_path: Optional[str],
    chat_history: ScrollableContainer,
) -> Optional[int]:
    """G·ª≠i y√™u c·∫ßu chat ƒë·∫øn API v√† hi·ªÉn th·ªã ph·∫£n h·ªìi m∆∞·ª£t m√† v·ªõi spinner."""
    json_payload = {"message": {"message": message}}
    if attached_file_path:
        try:
            with open(attached_file_path, "rb") as f:
                encoded_file = base64.b64encode(f.read()).decode("utf-8")
                filename = os.path.basename(attached_file_path)
                # Send file as an object so backend can know filename and detect images
                json_payload["file"] = {"content": encoded_file, "filename": filename}
        except Exception as e:
            chat_history.mount(Static(f"[red]L·ªói khi ƒë·ªçc file: {e}[/]"))
            return None
    params = {"conversation_id": conversation_id} if conversation_id else {}

    try:
        # Kh·ªüi t·∫°o bi·∫øn
        accumulated_content = ""
        ai_response_md = None
        initial_spinner = None
        initial_spinner_container = None
        response_spinner = None
        response_spinner_container = None
        is_using_tool = False
        pre_spinner_container = None
        
        # Bi·∫øn ƒë·ªÉ ƒëi·ªÅu khi·ªÉn t·∫ßn su·∫•t c·∫≠p nh·∫≠t
        last_update_time = 0
        update_interval = 0.1  # Ch·ªâ update m·ªói 100ms
        last_scroll_time = 0
        scroll_interval = 0.3  # Ch·ªâ scroll m·ªói 300ms
        
        # Bi·∫øn ƒë·ªÉ l∆∞u tool calls v√† search results
        current_tool_calls = []
        search_results_displayed = False
        search_notification_widget = None

        # HI·ªÇN TH·ªä SPINNER NGAY L·∫¨P T·ª®C - FIX: Lu√¥n hi·ªÉn th·ªã spinner ban ƒë·∫ßu
        initial_spinner = AnimatedSpinner("‚†ã", classes="spinner")
        initial_spinner.spinner_chars = THINKING_SPINNER
        initial_spinner.current_index = 0
        initial_spinner.styles.width = 1
        initial_spinner.styles.height = 1
        initial_spinner.styles.color = THINKING_COLOR
        initial_spinner_container = Static(
            f"  [{THINKING_COLOR}]{THINKING_PREFIX} Nhi ƒëang suy nghƒ©...[/]"
        )
        initial_spinner_container.styles.display = "block"
        initial_spinner_container.styles.padding = (0, 0, 0, 2)
        chat_history.mount(initial_spinner_container)
        initial_spinner_container.mount(initial_spinner)
        chat_history.scroll_end()

        # If no conversation_id provided, create a new conversation first and use its id
        if conversation_id is None:
            try:
                create_resp = await http_client.post("/conversations/")
                create_resp.raise_for_status()
                create_json = create_resp.json()
                # try to extract id from response
                new_id = (
                    create_json.get("id") if isinstance(create_json, dict) else None
                )
                if new_id is None:
                    # fallback: try common keys
                    new_id = (
                        create_json.get("conversation_id")
                        if isinstance(create_json, dict)
                        else None
                    )
                if new_id is None:
                    # couldn't determine id ‚Äî show message and continue without id
                    chat_history.mount(
                        Static(
                            "[yellow]T·∫°o cu·ªôc h·ªôi tho·∫°i m·ªõi nh∆∞ng kh√¥ng nh·∫≠n ƒë∆∞·ª£c ID. Ti·∫øp t·ª•c g·ª≠i m√† kh√¥ng c√≥ conversation_id.[/]"
                        )
                    )
                else:
                    conversation_id = new_id
            except httpx.HTTPStatusError as e:
                # read body safely
                body = ""
                try:
                    body = (await e.response.aread()).decode("utf-8", errors="replace")
                except Exception:
                    body = str(e.response)

                if e.response.status_code == 401 and "Token has expired" in body:
                    error_message = "Token c·ªßa b·∫°n ƒë√£ h·∫øt h·∫°n. Vui l√≤ng kh·ªüi ƒë·ªông l·∫°i."
                    if os.path.exists(TOKEN_FILE_PATH):
                        try:
                            os.remove(TOKEN_FILE_PATH)
                        except Exception as e:
                            chat_history.mount(
                                Static(f"[red]L·ªói khi x√≥a token: {e}[/red]")
                            )

                chat_history.mount(Static(f"[red]{error_message}[/]"))
                if initial_spinner_container:
                    try:
                        initial_spinner_container.remove()
                    except Exception:
                        pass
                return None
            except Exception as e:
                chat_history.mount(Static(f"[red]L·ªói khi t·∫°o cu·ªôc h·ªôi tho·∫°i: {e}[/]"))
                if initial_spinner_container:
                    try:
                        initial_spinner_container.remove()
                    except Exception:
                        pass
                return None

        # attach conversation_id param if we have one
        params = {"conversation_id": conversation_id} if conversation_id else {}

        async with http_client.stream(
            "POST", "/send", params=params, json=json_payload
        ) as response:
            response.raise_for_status()

            async for line in response.aiter_lines():
                if not line.startswith("data:"):
                    continue
                content = line[len("data:") :].strip()
                if not content:
                    continue
                try:
                    data_chunk = json.loads(content)
                except json.JSONDecodeError:
                    # non-json data ‚Äî treat as raw content
                    data_chunk = {"content": content}

                print(f"DEBUG: Stream chunk: {data_chunk}")  # Log full chunk

                # Conversation id ack
                if "conversation_id" in data_chunk:
                    conversation_id = data_chunk["conversation_id"]
                    continue

                # FIX: B·ªè qua x·ª≠ l√Ω typing indicator t·ª´ server, v√¨ ch√∫ng ta ƒë√£ c√≥ spinner ban ƒë·∫ßu
                if data_chunk.get("typing"):
                    continue

                # Done / error / tool_calls / content handling
                if data_chunk.get("done"):
                    if ai_response_md and accumulated_content:
                        ai_response_md.update(accumulated_content)
                        chat_history.scroll_end()
                    await asyncio.sleep(0.1)
                    break

                if data_chunk.get("error"):
                    if initial_spinner_container:
                        initial_spinner_container.remove()
                    if response_spinner_container:
                        response_spinner_container.remove()
                    chat_history.mount(
                        Static(f"[bold red]L·ªói Stream: {data_chunk['error']}[/]")
                    )
                    break

                # X·ª≠ l√Ω tool_calls - HI·ªÇN TH·ªä SEARCH RESULTS
                if (
                    data_chunk.get("tool_calls")
                    and isinstance(data_chunk["tool_calls"], list)
                    and data_chunk["tool_calls"]
                ):
                    print(f"DEBUG: Tool calls detected: {data_chunk['tool_calls']}")
                    
                    # L∆∞u tool calls hi·ªán t·∫°i
                    current_tool_calls = data_chunk["tool_calls"]
                    
                    # HI·ªÇN TH·ªä TH√îNG B√ÅO ƒêANG SEARCH
                    if not search_results_displayed:
                        search_notification_widget = Static(
                            f"[{TOOL_COLOR}]{TOOL_PREFIX} ƒêang t√¨m ki·∫øm th√¥ng tin...[/]"
                        )
                        search_notification_widget.styles.padding = (0, 0, 0, 2)
                        chat_history.mount(search_notification_widget)
                        chat_history.scroll_end()
                        search_results_displayed = True

                    if initial_spinner_container and not is_using_tool:
                        # change spinner visual to indicate a tool/search action
                        try:
                            initial_spinner.spinner_chars = TOOL_SPINNER
                            initial_spinner.current_index = 0
                            initial_spinner.styles.color = TOOL_COLOR
                        except Exception:
                            pass
                        initial_spinner_container.update(
                            f"  [{TOOL_COLOR}]{TOOL_PREFIX} Nhi ƒëang t√¨m...[/]"
                        )
                        initial_spinner_container.refresh()
                        is_using_tool = True
                    
                    # Hi·ªÉn th·ªã search results n·∫øu c√≥ trong tool calls
                    for tool_call in current_tool_calls:
                        if isinstance(tool_call, dict):
                            tool_type = tool_call.get("type", "")
                            tool_function = tool_call.get("function", {})
                            
                            # Hi·ªÉn th·ªã th√¥ng tin search
                            if tool_type == "web_search" or tool_function.get("name") == "web_search":
                                query = tool_function.get("arguments", {}).get("query", "")
                                if query:
                                    search_info = Static(
                                        f"[dim]{TOOL_PREFIX} T√¨m ki·∫øm: \"{query}\"[/dim]"
                                    )
                                    search_info.styles.padding = (0, 0, 0, 2)
                                    chat_history.mount(search_info)
                                    chat_history.scroll_end()
                            
                            # Hi·ªÉn th·ªã k·∫øt qu·∫£ search n·∫øu c√≥
                            if "result" in tool_call or "content" in tool_call:
                                result = tool_call.get("result") or tool_call.get("content")
                                if result:
                                    result_display = Static(
                                        f"[dim]{TOOL_PREFIX} K·∫øt qu·∫£ t√¨m ƒë∆∞·ª£c: {result[:200]}...[/dim]"
                                    )
                                    result_display.styles.padding = (0, 0, 0, 2)
                                    chat_history.mount(result_display)
                                    chat_history.scroll_end()
                    
                    # Create a placeholder response area so any tool output/content is shown
                    if not ai_response_md:
                        # ensure typing indicator removed
                        if initial_spinner_container:
                            try:
                                initial_spinner_container.remove()
                            except Exception:
                                pass
                            initial_spinner_container = None
                        chat_history.mount(Static(""))
                        ai_response_md = Markdown("")
                        chat_history.mount(ai_response_md)
                        # show a response spinner to indicate tool work
                        response_spinner = AnimatedSpinner("‚†ã", classes="spinner")
                        response_spinner.spinner_chars = THINKING_SPINNER
                        response_spinner.current_index = 0
                        response_spinner.styles.width = 1
                        response_spinner.styles.height = 1
                        response_spinner.styles.color = RESPONSE_TOOL_COLOR
                        response_spinner_container = Static("")
                        response_spinner_container.styles.display = "block"
                        response_spinner_container.styles.padding = (0, 0, 0, 2)
                        chat_history.mount(response_spinner_container)
                        response_spinner_container.mount(response_spinner)
                    continue

                # X·ª≠ l√Ω content - TH√äM HI·ªÇN TH·ªä SEARCH CONTEXT v√† GI·∫¢M T·∫¶N SU·∫§T UPDATE
                if data_chunk.get("content"):
                    decoded_content = (
                        data_chunk["content"].encode().decode("utf-8", errors="replace")
                    )
                    
                    # N·∫øu c√≥ search results tr∆∞·ªõc ƒë√≥, th√™m context v√†o content
                    if current_tool_calls and not accumulated_content:
                        search_context = "\n\n_D·ª±a tr√™n k·∫øt qu·∫£ t√¨m ki·∫øm..._\n\n"
                        decoded_content = search_context + decoded_content
                        current_tool_calls = []  # Reset sau khi ƒë√£ s·ª≠ d·ª•ng
                        
                        # X√≥a th√¥ng b√°o search ƒëang ch·ªù
                        if search_notification_widget:
                            try:
                                search_notification_widget.remove()
                            except Exception:
                                pass
                    
                    accumulated_content += decoded_content
                    
                    if not ai_response_md:
                        # FIX: X√≥a spinner ban ƒë·∫ßu khi b·∫Øt ƒë·∫ßu nh·∫≠n content
                        if initial_spinner_container:
                            try:
                                initial_spinner_container.remove()
                            except Exception:
                                pass
                            initial_spinner_container = None
                        
                        chat_history.mount(Static(""))
                        ai_response_md = Markdown("")
                        chat_history.mount(ai_response_md)
                        
                        # FIX: T·∫°o response spinner cho content stream
                        response_spinner = AnimatedSpinner("‚†ã", classes="spinner")
                        response_spinner.spinner_chars = THINKING_SPINNER
                        response_spinner.current_index = 0
                        response_spinner.styles.width = 1
                        response_spinner.styles.height = 1
                        response_spinner.styles.color = (
                            RESPONSE_TOOL_COLOR if is_using_tool else "white"
                        )
                        response_spinner_container = Static("")
                        response_spinner_container.styles.display = "block"
                        response_spinner_container.styles.padding = (0, 0, 0, 2)
                        chat_history.mount(response_spinner_container)
                        response_spinner_container.mount(response_spinner)
                    
                    # CH·ªà UPDATE KHI ƒê·ª¶ TH·ªúI GIAN - gi·∫£m gi·∫≠t lag
                    current_time = asyncio.get_event_loop().time()
                    if current_time - last_update_time >= update_interval:
                        if ai_response_md:
                            ai_response_md.update(accumulated_content)
                            last_update_time = current_time
                            
                            # CH·ªà SCROLL KHI ƒê·ª¶ TH·ªúI GIAN
                            if current_time - last_scroll_time >= scroll_interval:
                                chat_history.scroll_end()
                                last_scroll_time = current_time
                    
                    await asyncio.sleep(0.05)

        # Final update sau khi k·∫øt th√∫c stream
        if ai_response_md and accumulated_content:
            ai_response_md.update(accumulated_content)
            chat_history.scroll_end()
            await asyncio.sleep(0.1)

        # FIX: ƒê·∫£m b·∫£o x√≥a t·∫•t c·∫£ spinner sau khi k·∫øt th√∫c
        if response_spinner_container:
            response_spinner_container.remove()
        if initial_spinner_container:
            try:
                initial_spinner_container.remove()
            except Exception:
                pass

        return conversation_id

    except httpx.HTTPStatusError as e:
        # FIX: ƒê·∫£m b·∫£o x√≥a spinner khi c√≥ l·ªói
        if initial_spinner_container:
            initial_spinner_container.remove()
        if response_spinner_container:
            response_spinner_container.remove()
            
        # Safely read streaming response body (if any) to avoid ResponseNotRead
        body_text = ""
        try:
            # try to asynchronously read the response body if it's available
            body_bytes = await e.response.aread()
            body_text = body_bytes.decode("utf-8", errors="replace")
        except Exception:
            # fallback: try to get a repr or leave empty
            try:
                body_text = str(e.response)
            except Exception:
                body_text = "<kh√¥ng th·ªÉ ƒë·ªçc body>"

        chat_history.mount(
            Static(f"[bold red]L·ªói API {e.response.status_code}: {body_text}[/]")
        )
        if e.response.status_code in (401, 403):
            return "auth_error"
        return None
    except httpx.ConnectError:
        # FIX: ƒê·∫£m b·∫£o x√≥a spinner khi c√≥ l·ªói k·∫øt n·ªëi
        if initial_spinner_container:
            initial_spinner_container.remove()
        if response_spinner_container:
            response_spinner_container.remove()
            
        chat_history.mount(
            Static(f"[bold red]L·ªói k·∫øt n·ªëi t·ªõi {http_client.base_url}.[/]")
        )
        return None


async def fetch_conversations(
    http_client: httpx.AsyncClient, chat_history: ScrollableContainer
) -> None:
    """L·∫•y danh s√°ch c√°c cu·ªôc h·ªôi tho·∫°i t·ª´ API."""
    try:
        response = await http_client.get("/conversations/")
        response.raise_for_status()
        conversations = response.json()
        if not conversations:
            chat_history.mount(Static("Ch∆∞a c√≥ cu·ªôc h·ªôi tho·∫°i n√†o."))
            return
        history_text = "[bold]Danh s√°ch cu·ªôc h·ªôi tho·∫°i:[/]\n" + "\n".join(
            [
                f"- ID: {conv['id']} (T·∫°o l√∫c: {conv['created_at']})"
                for conv in conversations
            ]
        )
        chat_history.mount(Static(history_text))
        chat_history.scroll_end()
    except Exception as e:
        chat_history.mount(Static(f"[red]L·ªói khi t·∫£i l·ªãch s·ª≠: {e}[/]"))


async def load_conversation_history(
    http_client: httpx.AsyncClient, conv_id: int, chat_history: ScrollableContainer
) -> bool:  # Th√™m ki·ªÉu tr·∫£ v·ªÅ bool ƒë·ªÉ b√°o hi·ªáu th√†nh c√¥ng/th·∫•t b·∫°i
    """T·∫£i l·ªãch s·ª≠ cu·ªôc h·ªôi tho·∫°i t·ª´ API."""
    chat_history.query("*").remove()
    chat_history.mount(
        Static(f"ƒêang t·∫£i l·ªãch s·ª≠ cho cu·ªôc h·ªôi tho·∫°i [bold cyan]#{conv_id}[/]...")
    )
    try:
        response = await http_client.get(f"/messages/conversations/{conv_id}/messages")
        response.raise_for_status()
        messages = response.json()
        for msg in messages:
            chat_history.mount(Static(""))
            if msg["role"] == "user":
                chat_history.mount(Static(f">>> {msg['content']}"))
            else:
                chat_history.mount(Markdown(msg["content"]))
        chat_history.scroll_end()
        chat_history.mount(
            Static(f"B·∫°n ƒëang ·ªü trong cu·ªôc h·ªôi tho·∫°i [bold cyan]#{conv_id}[/].")
        )
        return True  # T·∫£i th√†nh c√¥ngset
    except httpx.HTTPStatusError as e:
        if e.response.status_code == 404:
            chat_history.mount(
                Static(f"[red]Conversation #{conv_id} kh√¥ng t·ªìn t·∫°i.[/]")
            )
        else:
            chat_history.mount(
                Static(
                    f"[red]L·ªói khi t·∫£i l·ªãch s·ª≠: {e.response.status_code} - {e.response.text}[/]"
                )
            )
        return False  # T·∫£i th·∫•t b·∫°i
    except Exception as e:
        chat_history.mount(Static(f"[red]L·ªói khi t·∫£i l·ªãch s·ª≠: {e}[/]"))
        return False  # T·∫£i th·∫•t b·∫°i


async def delete_current_conversation(
    http_client: httpx.AsyncClient,
    conversation_id: Optional[int],
    chat_history: ScrollableContainer,
) -> Optional[int]:
    """X√≥a cu·ªôc h·ªôi tho·∫°i hi·ªán t·∫°i ƒëang ƒë∆∞·ª£c t·∫£i."""
    if conversation_id is None:
        chat_history.mount(
            Static("[yellow]B·∫°n ƒëang ·ªü ngo√†i cu·ªôc tr√≤ chuy·ªán, kh√¥ng th·ªÉ x√≥a.[/]")
        )
        return None

    try:
        response = await http_client.delete(f"/conversations/{conversation_id}")
        response.raise_for_status()
        chat_history.query("*").remove()
        chat_history.scroll_end()
        return None

    except httpx.HTTPStatusError as e:
        chat_history.mount(
            Static(
                f"[bold red]L·ªói khi x√≥a cu·ªôc h·ªôi tho·∫°i: {e.response.status_code} - {e.response.text}[/]"
            )
        )
        chat_history.scroll_end()
        if e.response.status_code in (401, 403):
            return "auth_error"
        return conversation_id
    except httpx.ConnectError:
        chat_history.mount(
            Static(f"[bold red]L·ªói k·∫øt n·ªëi t·ªõi {http_client.base_url}.[/]")
        )
        chat_history.scroll_end()
        return conversation_id


async def delete_all_conversation(
    http_client: httpx.AsyncClient,
    chat_history: ScrollableContainer,
) -> Optional[int]:
    """X√≥a cu·ªôc h·ªôi tho·∫°i hi·ªán t·∫°i ƒëang ƒë∆∞·ª£c t·∫£i."""
    try:
        response = await http_client.delete(f"/conversations/")
        response.raise_for_status()
        chat_history.query("*").remove()
        chat_history.scroll_end()
        return None

    except httpx.HTTPStatusError as e:
        chat_history.mount(
            Static(
                f"[bold red]L·ªói khi x√≥a cu·ªôc h·ªôi tho·∫°i: {e.response.status_code} - {e.response.text}[/]"
            )
        )
        chat_history.scroll_end()
        if e.response.status_code in (401, 403):
            return "auth_error"

    except httpx.ConnectError:
        chat_history.mount(
            Static(f"[bold red]L·ªói k·∫øt n·ªëi t·ªõi {http_client.base_url}.[/]")
        )
        chat_history.scroll_end()
