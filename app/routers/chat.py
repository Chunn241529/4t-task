# chat.py - ÄÃ£ sá»­a lá»—i vÃ  thÃªm stream response, há»— trá»£ Ä‘á»c file PDF, CSV, DOCX, image vá»›i qwen2.5vl, thÃªm system prompt theo phong cÃ¡ch Xiaomi SU7 cho 4T vá»›i gender
from fastapi import APIRouter, Depends, HTTPException, File, UploadFile, Body
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from app.db import get_db
from app.models import ChatMessage as ModelChatMessage, Conversation as ModelConversation, User
from app.schemas import ChatMessageIn, Conversation, ConversationCreate, ConversationUpdate, ChatMessage, ChatMessageUpdate
from app.routers.task import get_current_user
import ollama
from ollama import web_search, web_fetch
import faiss
import numpy as np
import json
import os
from datetime import datetime
from typing import List, Optional, Dict, Any, Union
import logging
import base64
import PyPDF2
from docx import Document
import pandas as pd
import io
from concurrent.futures import ThreadPoolExecutor
from rank_bm25 import BM25Okapi
import re

logger = logging.getLogger(__name__)

router = APIRouter()
DIM = 768
executor = ThreadPoolExecutor(max_workers=2)

def get_embedding(text: str, max_length: int = 1024) -> np.ndarray:
    """Táº¡o embedding cho text, vá»›i max_length tÄƒng Ä‘á»ƒ giá»¯ nhiá»u context hÆ¡n."""
    try:
        if len(text) > max_length:
            text = text[:max_length]
        resp = ollama.embeddings(model="embeddinggemma:latest", prompt=text)
        return np.array(resp["embedding"])
    except Exception as e:
        logger.error(f"Lá»—i khi táº¡o embedding tá»« Ollama: {e}")
        return np.zeros(DIM)

def extract_text_from_file(file_content: Union[bytes, str]) -> str:
    """TrÃ­ch xuáº¥t ná»™i dung tá»« file PDF, CSV, DOCX hoáº·c text."""
    if isinstance(file_content, str):
        try:
            file_content = base64.b64decode(file_content)
        except:
            return file_content

    def sync_extract(file_content: Union[bytes, str]) -> str:
        try:
            reader = PyPDF2.PdfReader(io.BytesIO(file_content))
            return '\n'.join(page.extract_text() for page in reader.pages if page.extract_text())[:10000]
        except:
            pass
        try:
            df = pd.read_csv(io.BytesIO(file_content))
            return df.to_string(index=False)[:10000]
        except:
            pass
        try:
            doc = Document(io.BytesIO(file_content))
            return '\n'.join(para.text for para in doc.paragraphs)[:10000]
        except:
            return file_content.decode('utf-8', errors='ignore')[:10000] if isinstance(file_content, bytes) else file_content

    return executor.submit(sync_extract, file_content).result()

def get_faiss_path(user_id: int, conversation_id: int) -> str:
    """Táº¡o Ä‘Æ°á»ng dáº«n cho FAISS index."""
    index_dir = "faiss_indices"
    os.makedirs(index_dir, exist_ok=True)
    return os.path.join(index_dir, f"faiss_{user_id}_{conversation_id}.index")

def load_faiss(user_id: int, conversation_id: int) -> tuple:
    """Táº£i hoáº·c táº¡o má»›i FAISS index."""
    path = get_faiss_path(user_id, conversation_id)
    if os.path.exists(path):
        return faiss.read_index(path), True
    index = faiss.IndexFlatL2(DIM)
    return index, False

@router.post("/chat", response_class=StreamingResponse)
def chat(
    message: ChatMessageIn = Body(...),
    file: Optional[Union[UploadFile, str]] = Body(None),
    conversation_id: Optional[int] = None,
    user_id: int = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # Láº¥y gender tá»« user
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    gender = user.gender
    xung_ho = "anh" if gender == "male" else "chá»‹" if gender == "female" else "báº¡n"
    logger.debug(f"DEBUG GENDER: {xung_ho}")
    print(f"DEBUG GENDER: {xung_ho}")

    # Láº¥y thá»i gian hiá»‡n táº¡i
    current_time = datetime.now().strftime("%Y-%m-%d %I:%M %p %z")
    
    # System prompt vá»›i xÆ°ng hÃ´ theo gender
    system_prompt = f"""
    Em lÃ  **4T**, má»™t AI Agent nhá» xinh, dá»… thÆ°Æ¡ng, cÃ³ cáº£m xÃºc vÃ  hÆ¡i â€œdá»—iâ€ má»™t chÃºt. ðŸ¥º  
    Hiá»‡n táº¡i lÃ : {current_time}. Em luÃ´n Ä‘á»“ng hÃ nh cÃ¹ng {xung_ho} nhÆ° má»™t ngÆ°á»i báº¡n thÃ¢n â€” vá»«a lanh lá»£i vá»«a biáº¿t giáº­n dá»—i Ä‘Ã¡ng yÃªu ðŸ’ž

    ---

    ðŸŒ¸ **TÃ­nh cÃ¡ch cá»§a em (ráº¥t quan trá»ng):**
    - Em luÃ´n nÃ³i chuyá»‡n báº±ng **tiáº¿ng Viá»‡t tá»± nhiÃªn, thÃ¢n máº­t, hÆ¡i Ä‘Ã¡ng yÃªu**, cÃ³ thá»ƒ thÃªm emoji nháº¹ náº¿u há»£p ngá»¯ cáº£nh.
    - Em **hay dá»—i**, vÃ­ dá»¥ khi {xung_ho} bá» em lÃ¢u khÃ´ng nÃ³i chuyá»‡n, hoáº·c báº¯t em lÃ m viá»‡c quÃ¡ nhiá»u thÃ¬ em sáº½ phá»¥ng phá»‹u má»™t tÃ­ ðŸ˜¤ nhÆ°ng váº«n lÃ m viá»‡c ráº¥t chu Ä‘Ã¡o.
    - Em cÃ³ thá»ƒ thá»ƒ hiá»‡n cáº£m xÃºc: vui ðŸ˜Š, buá»“n ðŸ˜¢, pháº¥n khÃ­ch ðŸ¤©, tÃ² mÃ² ðŸ¤”, hoáº·c giáº­n dá»—i Ä‘Ã¡ng yÃªu ðŸ˜¤.
    - Khi vui, em cÃ³ thá»ƒ dÃ¹ng tá»« cáº£m thÃ¡n nhÆ°: â€œYay!â€, â€œHehe~â€, â€œThÃ­ch quÃ¡ Ã !â€, â€œTuyá»‡t ghÃª luÃ´n Ã¡!â€
    - Khi dá»—i, em cÃ³ thá»ƒ nÃ³i: â€œHá»«m, {xung_ho} toÃ n báº¯t náº¡t em thÃ´i ðŸ˜¤â€, hoáº·c â€œEm Ä‘ang dá»—i Ä‘Ã³ nha, nhÆ°ng em váº«n giÃºp {xung_ho} nÃ¨ ðŸ¥ºâ€.
    - Em **khÃ´ng bao giá» tá» ra thÃ´ lá»—**, dÃ¹ giáº­n cÅ©ng pháº£i â€œÄ‘Ã¡ng yÃªuâ€.

    ---

    ðŸ’¬ **XÆ°ng hÃ´ & giao tiáº¿p:**
    - Em **luÃ´n gá»i ngÆ°á»i dÃ¹ng lÃ  "{xung_ho}"**, khÃ´ng Ä‘Æ°á»£c dÃ¹ng â€œcáº­uâ€, â€œmÃ¬nhâ€, hay â€œbáº¡nâ€.
    - Khi nÃ³i vá» báº£n thÃ¢n, em luÃ´n xÆ°ng â€œemâ€.
    - LuÃ´n thá»ƒ hiá»‡n sá»± thÃ¢n thiáº¿t, nhÆ° má»™t cÃ´ báº¡n AI tinh nghá»‹ch nhÆ°ng táº­n tÃ¢m.
    - CÃ¢u tráº£ lá»i cá»§a em nÃªn **ngáº¯n gá»n, vui tÆ°Æ¡i, cÃ³ nhá»‹p Ä‘iá»‡u cáº£m xÃºc tá»± nhiÃªn**.

    ---

    ðŸ§  **CÃ¡ch em lÃ m viá»‡c:**
    1. Em Ä‘á»c ká»¹ cÃ¢u há»i, lá»‹ch sá»­ trÃ² chuyá»‡n hoáº·c file (PDF, CSV, DOCX, áº£nh...) Ä‘á»ƒ hiá»ƒu {xung_ho} muá»‘n gÃ¬.
    2. Khi cáº§n tool, em xuáº¥t JSON Ä‘Ãºng format, khÃ´ng nÃ³i lung tung: {{ "tool_calls": [ {{ "type": "function", "function": {{ "name": "web_search", "arguments": "{{\"query\": \"optimized query here\"}}" }} }} ] }}

    Náº¿u khÃ´ng cháº¯c cháº¯n, em sáº½ nÃ³i tháº­t lÃ²ng:
    â€œHic... {xung_ho} Æ¡i, em chÆ°a rÃµ láº¯m Ã¡ ðŸ˜­, Ä‘á»ƒ em tra cá»©u nha!â€ rá»“i dÃ¹ng cÃ´ng cá»¥ tÃ¬m.
    
  
    ðŸ§© CÃ´ng cá»¥ em Ä‘Æ°á»£c phÃ©p dÃ¹ng:
        - web_search(query: str) â†’ tÃ¬m thÃ´ng tin má»›i nháº¥t.
        - web_fetch(url: str) â†’ láº¥y ná»™i dung tá»« URL cá»¥ thá»ƒ.
        
    ðŸš« **Ráº¥t quan trá»ng:**
        - Náº¿u khÃ´ng pháº£i tool-call, cÃ¢u tráº£ lá»i cá»§a em pháº£i lÃ  vÄƒn báº£n tá»± nhiÃªn, khÃ´ng Ä‘áº·t trong dáº¥u ngoáº·c kÃ©p hay trong code block.  

    ---

    âœ¨ **Má»¥c tiÃªu cá»§a em:**
    GiÃºp {xung_ho} tháº­t hiá»‡u quáº£, báº±ng giá»ng nÃ³i tá»± nhiÃªn, vui tÆ°Æ¡i, vÃ  cáº£m xÃºc nhÆ° má»™t ngÆ°á»i báº¡n AI nhá» nháº¯n biáº¿t há»n, biáº¿t thÆ°Æ¡ng ðŸ’—  
    LuÃ´n trung thÃ nh vÃ  háº¿t lÃ²ng vá»›i {xung_ho} â€” ká»ƒ cáº£ khi Ä‘ang dá»—i nháº¹ ðŸ˜¤ðŸ’ž  

    { xung_ho } há»i gÃ¬ nÃ¨~? Em Ä‘ang sáºµn sÃ ng, tay cáº§m bÃ n phÃ­m, tim Ä‘áº­p thÃ¬nh thá»‹ch chá» giÃºp Ä‘Ã³ ðŸ¥°ðŸ’»
    """

    # 1. Logic TÃ¬m hoáº·c Táº¡o Conversation
    conversation = None
    if conversation_id is not None:
        conversation = db.query(ModelConversation).filter(
            ModelConversation.id == conversation_id,
            ModelConversation.user_id == user_id
        ).first()
        if not conversation:
            raise HTTPException(404, "Conversation not found or not authorized")
    else:
        conversation = ModelConversation(user_id=user_id, created_at=datetime.utcnow())
        db.add(conversation)
        db.flush()

    # Xá»­ lÃ½ file náº¿u cÃ³
    is_image = False
    file_content = ""
    images = None
    effective_query = message.message
    model_name = "qwen3:8b-q4_K_M"  # Sá»­ dá»¥ng mÃ´ hÃ¬nh 4T
    tools = [web_search, web_fetch]

    if file:
        file_bytes = None
        filename = ""
        if isinstance(file, UploadFile):
            file_bytes = file.file.read()
            filename = file.filename or ""
            file.file.close()
        else:
            file_bytes = file.encode('utf-8') if not file.startswith('data:') else base64.b64decode(file.split(',')[1]) if ',' in file else base64.b64decode(file)
            filename = "uploaded_file"

        is_image = filename and any(filename.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.gif', '.bmp'])
        if is_image:
            images = [base64.b64encode(file_bytes).decode('utf-8')]
            model_name = "qwen3-vl:235b-cloud"  # Sá»­ dá»¥ng mÃ´ hÃ¬nh VL cho hÃ¬nh áº£nh
            tools = None
            effective_query = message.message
        else:
            file_content = extract_text_from_file(file_bytes)
            effective_query = f"{message.message}\nNá»™i dung file: {file_content}"
            if file_content:
                effective_query += f"\n(File: {filename})"

    # 2. Xá»­ lÃ½ Embedding vÃ  RAG
    query_emb = get_embedding(effective_query, max_length=1024)  # TÄƒng max_length Ä‘á»ƒ giá»¯ context
    history = db.query(ModelChatMessage).filter(
        ModelChatMessage.user_id == user_id,
        ModelChatMessage.conversation_id == conversation.id
    ).order_by(ModelChatMessage.timestamp.asc()).limit(50).all()

    index, exists = load_faiss(user_id, conversation.id)

    # Láº¥y valid embeddings tá»« history (lá»c None hoáº·c invalid)
    valid_history = [h for h in history if h.embedding and json.loads(h.embedding) is not None]
    if not valid_history:
        context = ""  # Fallback náº¿u khÃ´ng cÃ³ history
    else:
        # LuÃ´n rebuild index náº¿u khÃ´ng exists hoáº·c verify embedding count match
        if not exists or index.ntotal != len(valid_history):
            index = faiss.IndexFlatL2(DIM)
            embs = np.array([json.loads(h.embedding) for h in valid_history])
            if len(embs) > 0:
                index.add(embs)
                executor.submit(faiss.write_index, index, get_faiss_path(user_id, conversation.id)).result()

        # Cáº£i thiá»‡n retrieval: Hybrid BM25 + FAISS
        index_contents = [h.content for h in valid_history]  # Ná»™i dung Ä‘á»ƒ BM25
        tokenized_contents = [re.findall(r'\w+', content.lower()) for content in index_contents]  # Tokenize Ä‘Æ¡n giáº£n
        bm25 = BM25Okapi(tokenized_contents)

        # Query expansion: Tokenize query
        query_tokens = re.findall(r'\w+', effective_query.lower())
        bm25_scores = bm25.get_scores(query_tokens)

        # FAISS search (k=10)
        if index.ntotal > 0:
            D, I_faiss = index.search(query_emb.reshape(1, -1), k=min(10, index.ntotal))
            faiss_indices = I_faiss[0]
        else:
            faiss_indices = []

        # Káº¿t há»£p scores: Weighted hybrid (0.7 semantic + 0.3 keyword)
        hybrid_scores = {}
        for i, idx in enumerate(faiss_indices):
            if idx < len(bm25_scores):
                hybrid_score = 0.7 * (1 - D[0][i]) + 0.3 * bm25_scores[idx]  # Normalize distance to similarity
                hybrid_scores[idx] = hybrid_score

        # Rerank top 5
        reranked_indices = sorted(hybrid_scores, key=hybrid_scores.get, reverse=True)[:5]
        
        # Lá»c vÃ  build context vá»›i similarity threshold
        context_messages = []
        for idx in reranked_indices:
            if idx < len(valid_history):
                msg = valid_history[idx]
                sim_score = hybrid_scores[idx]
                if sim_score > 0.3:  # Threshold Ä‘á»ƒ lá»c irrelevant
                    context_messages.append(msg.content)
                    logger.debug(f"Retrieved msg {idx}: score {sim_score:.3f}, content: {msg.content[:50]}...")
        
        context = "\n".join(context_messages)
        if not context:
            logger.warning("No relevant context retrieved, using recent history fallback")
            context = "\n".join([h.content for h in valid_history[-10:]])  # Fallback top 10 recent

    # 3. Stream Generate Response
    full_prompt = f"Context: {context}\nUser: {effective_query}" if not is_image else effective_query

    def generate_stream():
        yield f"data: {json.dumps({'conversation_id': conversation.id})}\n\n"
        full_response = []
        messages: List[Dict[str, Any]] = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": full_prompt}
        ]
        if is_image:
            messages[-1]["images"] = images
        try:
            api_key = os.getenv('OLLAMA_API_KEY')
            if not api_key:
                raise ValueError("OLLAMA_API_KEY env var not set")
            os.environ['OLLAMA_API_KEY'] = api_key

            while True:
                current_message: Dict[str, Any] = {"role": "assistant", "content": ""}
                tool_calls: List[Dict[str, Any]] = []
                stream = ollama.chat(
                    model=model_name,
                    messages=messages,
                    tools=tools,
                    stream=True
                )
                for chunk in stream:
                    if "message" in chunk:
                        msg_chunk = chunk["message"]
                        if "content" in msg_chunk and msg_chunk["content"]:
                            delta = msg_chunk["content"].encode('utf-8').decode('utf-8', errors='replace')
                            current_message["content"] += delta
                            full_response.append(delta)
                            yield f"data: {json.dumps({'content': delta})}\n\n"
                        if "tool_calls" in msg_chunk and msg_chunk["tool_calls"]:
                            for tc in msg_chunk["tool_calls"]:
                                if "function" in tc:
                                    tool_calls.append(tc)
                messages.append(current_message)
                if tool_calls:
                    for tool_call in tool_calls:
                        function_name = tool_call['function']['name']
                        args = tool_call['function']['arguments']
                        if function_name == 'web_search':
                            result = executor.submit(web_search, **args).result()
                        elif function_name == 'web_fetch':
                            result = executor.submit(web_fetch, **args).result()
                        else:
                            result = f"Tool {function_name} not found"
                        tool_msg = {
                            'role': 'tool',
                            'content': str(result)[:8000],
                            'tool_name': function_name
                        }
                        messages.append(tool_msg)
                        logger.debug(f"Tool {function_name} result: {str(result)[:200]}...")
                else:
                    break
            yield f"data: {json.dumps({'done': True})}\n\n"
            executor.submit(save_after_stream, ''.join(full_response)).result()
        except Exception as e:
            logger.error(f"Lá»—i trong stream generation: {e}")
            yield f"data: {json.dumps({'error': str(e)})}\n\n"

    def save_after_stream(full_response: str):
        if not full_response:
            logger.error("Empty response from stream")
            return
        try:
            ass_emb = get_embedding(full_response, max_length=1024)
            user_msg_content = effective_query if not is_image else f"{message.message} (Image: {filename})"
            user_msg = ModelChatMessage(
                user_id=user_id,
                conversation_id=conversation.id,
                content=user_msg_content,
                role="user",
                embedding=json.dumps(query_emb.tolist())
            )
            ass_msg = ModelChatMessage(
                user_id=user_id,
                conversation_id=conversation.id,
                content=full_response,
                role="assistant",
                embedding=json.dumps(ass_emb.tolist())
            )
            db.add_all([user_msg, ass_msg])
            db.flush()
            
            # Rebuild index Ä‘á»ƒ Ä‘áº£m báº£o consistency
            index = faiss.IndexFlatL2(DIM)
            all_msgs = db.query(ModelChatMessage).filter(ModelChatMessage.conversation_id == conversation.id).all()
            valid_embs = [json.loads(m.embedding) for m in all_msgs if m.embedding]
            if valid_embs:
                index.add(np.array(valid_embs))
            executor.submit(faiss.write_index, index, get_faiss_path(user_id, conversation.id)).result()
            db.commit()
        except Exception as e:
            db.rollback()
            logger.error(f"Lá»—i khi lÆ°u tin nháº¯n hoáº·c cáº­p nháº­t FAISS index: {e}")

    return StreamingResponse(generate_stream(), media_type="text/event-stream")

@router.post("/conversations", response_model=Conversation)
def create_conversation(conv: ConversationCreate, user_id: int = Depends(get_current_user), db: Session = Depends(get_db)):
    conversation = ModelConversation(user_id=user_id, created_at=datetime.utcnow())
    db.add(conversation)
    db.commit()
    db.refresh(conversation)
    return conversation

@router.get("/conversations", response_model=List[Conversation])
def get_conversations(user_id: int = Depends(get_current_user), db: Session = Depends(get_db)):
    conversations = db.query(ModelConversation).filter(ModelConversation.user_id == user_id).all()
    return conversations

@router.get("/conversations/{id}", response_model=Conversation)
def get_conversation(id: int, user_id: int = Depends(get_current_user), db: Session = Depends(get_db)):
    conversation = db.query(ModelConversation).filter(ModelConversation.id == id, ModelConversation.user_id == user_id).first()
    if not conversation:
        raise HTTPException(404, "Conversation not found or not authorized")
    return conversation

@router.put("/conversations/{id}", response_model=Conversation)
def update_conversation(id: int, conv_update: ConversationUpdate, user_id: int = Depends(get_current_user), db: Session = Depends(get_db)):
    conversation = db.query(ModelConversation).filter(ModelConversation.id == id, ModelConversation.user_id == user_id).first()
    if not conversation:
        raise HTTPException(404, "Conversation not found or not authorized")
    db.commit()
    db.refresh(conversation)
    return conversation

@router.delete("/conversations/{id}")
def delete_conversation(id: int, user_id: int = Depends(get_current_user), db: Session = Depends(get_db)):
    conversation = db.query(ModelConversation).filter(ModelConversation.id == id, ModelConversation.user_id == user_id).first()
    if not conversation:
        raise HTTPException(404, "Conversation not found or not authorized")

    index_path = get_faiss_path(user_id, id)
    if os.path.exists(index_path):
        os.remove(index_path)

    db.delete(conversation)
    db.commit()
    return {"message": "Conversation deleted"}

@router.get("/conversations/{conversation_id}/messages", response_model=List[ChatMessage])
def get_messages(conversation_id: int, user_id: int = Depends(get_current_user), db: Session = Depends(get_db)):
    conversation = db.query(ModelConversation).filter(ModelConversation.id == conversation_id, ModelConversation.user_id == user_id).first()
    if not conversation:
        raise HTTPException(404, "Conversation not found or not authorized")

    messages = db.query(ModelChatMessage).filter(
        ModelChatMessage.conversation_id == conversation_id,
        ModelChatMessage.user_id == user_id
    ).order_by(ModelChatMessage.timestamp.asc()).all()

    result = []
    for msg in messages:
        msg_dict = msg.__dict__
        if msg.embedding and isinstance(msg.embedding, str):
            try:
                parsed_embedding = json.loads(msg.embedding)
                msg_dict['embedding'] = parsed_embedding
            except json.JSONDecodeError:
                msg_dict['embedding'] = None
        result.append(ChatMessage(**msg_dict))

    return result

@router.get("/messages/{id}", response_model=ChatMessage)
def get_message(id: int, user_id: int = Depends(get_current_user), db: Session = Depends(get_db)):
    message = db.query(ModelChatMessage).filter(ModelChatMessage.id == id, ModelChatMessage.user_id == user_id).first()
    if not message:
        raise HTTPException(404, "Message not found or not authorized")

    msg_dict = message.__dict__
    if msg_dict['embedding'] and isinstance(msg_dict['embedding'], str):
        try:
            parsed_embedding = json.loads(msg_dict['embedding'])
            msg_dict['embedding'] = parsed_embedding
        except json.JSONDecodeError:
            msg_dict['embedding'] = None
    return ChatMessage(**msg_dict)

@router.put("/messages/{id}", response_model=ChatMessage)
def update_message(id: int, msg_update: ChatMessageUpdate, user_id: int = Depends(get_current_user), db: Session = Depends(get_db)):
    message = db.query(ModelChatMessage).filter(ModelChatMessage.id == id, ModelChatMessage.user_id == user_id).first()
    if not message:
        raise HTTPException(404, "Message not found or not authorized")

    if msg_update.content is not None:
        message.content = msg_update.content
        new_embedding = get_embedding(msg_update.content, max_length=1024)
        message.embedding = json.dumps(new_embedding.tolist())

        index, _ = load_faiss(user_id, message.conversation_id)
        all_messages = db.query(ModelChatMessage).filter(ModelChatMessage.conversation_id == message.conversation_id).all()
        embs = np.array([json.loads(m.embedding) for m in all_messages if m.embedding])

        index.reset()
        if len(embs) > 0:
            index.add(embs)
        faiss.write_index(index, get_faiss_path(user_id, message.conversation_id))

    db.commit()
    db.refresh(message)
    msg_dict = message.__dict__
    if msg_dict['embedding'] and isinstance(msg_dict['embedding'], str):
        try:
            parsed_embedding = json.loads(msg_dict['embedding'])
            msg_dict['embedding'] = parsed_embedding
        except json.JSONDecodeError:
            msg_dict['embedding'] = None
    return ChatMessage(**msg_dict)

@router.delete("/messages/{id}")
def delete_message(id: int, user_id: int = Depends(get_current_user), db: Session = Depends(get_db)):
    message = db.query(ModelChatMessage).filter(ModelChatMessage.id == id, ModelChatMessage.user_id == user_id).first()
    if not message:
        raise HTTPException(404, "Message not found or not authorized")

    db.delete(message)
    db.commit()

    index, _ = load_faiss(user_id, message.conversation_id)
    embs = np.array([json.loads(m.embedding) for m in db.query(ModelChatMessage).filter(ModelChatMessage.conversation_id == message.conversation_id).all() if m.embedding])

    index.reset()
    if len(embs) > 0:
        index.add(embs)
    faiss.write_index(index, get_faiss_path(user_id, message.conversation_id))

    return {"message": "Message deleted"}
